{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainstates import BrainStates\n",
    "import numpy as np\n",
    "from scipy.signal.windows import hamming\n",
    "import scipy.io as sio\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from plot_points import plot_points\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid1, grid2 = np.meshgrid([30,40,50,60,70], [2,8,16,32])\n",
    "combinations = np.dstack((grid1, grid2)).reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_list = np.zeros((len(combinations), 2, 2))\n",
    "for counter, (WINDOW_SIZE, STRIDE) in tqdm(enumerate(combinations)):\n",
    "    MAIN_DIR = \"/home/usuario/disco1/proyectos/2023-Coma3D\"\n",
    "    N_CLUSTERS = 3\n",
    "    REPLICATES = 1000\n",
    "    GROUP = \"patients\"\n",
    "\n",
    "    subs = glob(f\"{MAIN_DIR}/Preprocess/parcellation/DMN_all/*.mat\")\n",
    "    subs = sorted(subs)\n",
    "    n_time = 500\n",
    "    n_rois = 34\n",
    "    data = np.zeros((n_time, n_rois, len(subs)))\n",
    "    for i, sub in enumerate(subs):\n",
    "        data[:,:,i] = sio.loadmat(sub)[\"func_roi\"].T\n",
    "\n",
    "    if GROUP == \"patients\":\n",
    "        data_conditions = {\"patients\": data[:,:,0:25]}\n",
    "        path = f\"{MAIN_DIR}/scripts/brainstates/pipeline/outputs/patients/{N_CLUSTERS}/{WINDOW_SIZE}_{STRIDE}\"\n",
    "    else:\n",
    "        data_conditions = {\"patients\": data[:,:,0:25], \"controls\": data[:,:,25:]}\n",
    "        path = f\"{MAIN_DIR}/scripts/brainstates/pipeline/outputs/all/{N_CLUSTERS}/{WINDOW_SIZE}_{STRIDE}\"\n",
    "\n",
    "\n",
    "    b = BrainStates(\n",
    "        from_dict=data_conditions,\n",
    "        output_path=path,\n",
    "        export_vars=True,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    b.run(\n",
    "        window_size=WINDOW_SIZE,\n",
    "        stride=STRIDE,\n",
    "        tapering_function=None,\n",
    "        subsampling=1,\n",
    "        n_clusters=N_CLUSTERS,\n",
    "        n_init=REPLICATES\n",
    "    )\n",
    "\n",
    "\n",
    "    probs_patients = b.get_probs()[\"patients\"]\n",
    "    if GROUP != \"patients\":\n",
    "        probs_controls = b.get_probs()[\"controls\"]\n",
    "\n",
    "    patients_data = data[:,:,0:25].copy()\n",
    "    IGNORE_OUTCOME = [6, 16] # we don't have the data on these ones\n",
    "    IGNORE_DATA = [6, 17] # we don't have the outcomes on these ones\n",
    "    patients_data = np.delete(patients_data, IGNORE_DATA, axis=2)\n",
    "    for iSub in tqdm(range(23)):\n",
    "        patients_data_train = np.delete(patients_data, iSub, axis=2)\n",
    "        data_conditions = {\"patients\": patients_data_train}\n",
    "        b = BrainStates(\n",
    "            from_dict=data_conditions,\n",
    "            output_path=f\"{MAIN_DIR}/scripts/brainstates/pipeline/outputs/leave_one_out/{N_CLUSTERS}/{WINDOW_SIZE}_{STRIDE}\",\n",
    "        )\n",
    "        b.run(\n",
    "            window_size=WINDOW_SIZE,\n",
    "            stride=STRIDE,\n",
    "            tapering_function=None,\n",
    "            subsampling=1,\n",
    "            n_clusters=N_CLUSTERS,\n",
    "            n_init=REPLICATES\n",
    "        )\n",
    "        prob = b.calculate_prob(b.dfc_all_pipeline.fit_transform(np.expand_dims(patients_data[:,:,iSub], axis=2)))\n",
    "\n",
    "        sio.savemat(f\"{MAIN_DIR}/scripts/brainstates/pipeline/outputs/leave_one_out/{N_CLUSTERS}/{WINDOW_SIZE}_{STRIDE}/{iSub}.mat\", {\"prob\": prob, \"probs\": b.get_probs()[\"patients\"], \"entropy\": b.entropy})\n",
    "\n",
    "    # outcomes\n",
    "\n",
    "    INPUT_PATIENTS_DIR = f\"{MAIN_DIR}/scripts/brainstates/pipeline/outputs/patients/{N_CLUSTERS}/{WINDOW_SIZE}_{STRIDE}\"\n",
    "    INPUT_ALL_DIR = f\"{MAIN_DIR}/scripts/brainstates/pipeline/outputs/all/{N_CLUSTERS}/{WINDOW_SIZE}_{STRIDE}\"\n",
    "    INPUT_LEAVE_ONE_OUT = f\"{MAIN_DIR}/scripts/brainstates/pipeline/outputs/leave_one_out/{N_CLUSTERS}/{WINDOW_SIZE}_{STRIDE}\"\n",
    "    IGNORE_OUTCOME = [6, 16] # we don't have the data on these ones\n",
    "    IGNORE_DATA = [6, 17] # we don't have the outcomes on these ones\n",
    "\n",
    "    outcomes = pd.read_csv(f\"{MAIN_DIR}/scripts/demographics.csv\")\n",
    "    outcomes.drop(index=IGNORE_OUTCOME, inplace=True)\n",
    "    outcomes[\"etiology\"] = outcomes[\"etiology\"].astype(\"category\")\n",
    "    outcomes[\"sex\"] = outcomes[\"sex\"].astype(\"category\")\n",
    "    outcomes[\"binary_outcome_cat\"] = list(map(lambda x: \"WORSE\" if x == 0 else \"BETTER\", outcomes[\"binary_outcome\"]))\n",
    "    outcomes[\"binary_outcome_cat\"] = outcomes[\"binary_outcome_cat\"].astype(\"category\")\n",
    "\n",
    "    # Import relevant variables and match the corresponding outcome data\n",
    "    probs = sio.loadmat(f\"{INPUT_PATIENTS_DIR}/probs_patients.mat\")[\"probs\"]\n",
    "\n",
    "    entropy = sio.loadmat(f\"{INPUT_PATIENTS_DIR}/entropy.mat\")[\"H\"]\n",
    "    probs = np.delete(probs, IGNORE_DATA, axis=0)\n",
    "    outcomes[\"prob1\"] = probs[:,0]\n",
    "    outcomes[\"prob2\"] = probs[:,1]\n",
    "    #outcomes[\"prob3\"] = probs[:,2]\n",
    "    outcomes[\"we\"] = np.sum(probs*np.repeat(entropy, 23, axis=0), axis=1)\n",
    "\n",
    "    predicted_outcome = np.zeros(23)\n",
    "    for iSub in range(23):\n",
    "        prob = sio.loadmat(f\"{INPUT_LEAVE_ONE_OUT}/{iSub}.mat\")[\"prob\"]\n",
    "        probs = sio.loadmat(f\"{INPUT_LEAVE_ONE_OUT}/{iSub}.mat\")[\"probs\"]\n",
    "        entropy = sio.loadmat(f\"{INPUT_LEAVE_ONE_OUT}/{iSub}.mat\")[\"entropy\"]\n",
    "        \n",
    "        outcomes_test = outcomes.copy()\n",
    "        outcomes_test.drop(outcomes_test.index[iSub], inplace=True)\n",
    "        outcomes_test[\"we\"] = np.sum(probs*np.repeat(entropy, 22, axis=0), axis=1)\n",
    "\n",
    "        worse = outcomes_test[outcomes_test[\"binary_outcome\"] == 0][\"we\"].mean()\n",
    "        better = outcomes_test[outcomes_test[\"binary_outcome\"] == 1][\"we\"].mean()\n",
    "        we = np.sum(prob*entropy)\n",
    "        if we > (worse+better)/2:\n",
    "            predicted_outcome[iSub] = 1\n",
    "        else:\n",
    "            predicted_outcome[iSub] = 0\n",
    "\n",
    "    outcomes[\"predicted_outcome\"] = predicted_outcome.astype(int)\n",
    "    cm = confusion_matrix(outcomes[\"binary_outcome\"].values, outcomes[\"predicted_outcome\"].values, normalize=\"true\")\n",
    "    cm_list[counter, :, :] = cm\n",
    "    #disp = ConfusionMatrixDisplay(cm)\n",
    "    #disp.plot()\n",
    "\n",
    "    #plt.savefig(f\"{INPUT_LEAVE_ONE_OUT}/figures/confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = cm_list[:,0,0]\n",
    "tn = cm_list[:,1,1]\n",
    "plt.plot(tp)\n",
    "plt.plot(tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp[9], tn[9], combinations[9]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
